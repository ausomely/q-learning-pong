Using cuda
#Frame: 10000, preparing replay buffer
#Frame: 20000, Loss: 0.000404
Last-10 average reward: -19.200000
#Frame: 30000, Loss: 0.000330
Last-10 average reward: -17.400000
#Frame: 40000, Loss: 0.000304
Last-10 average reward: -17.500000
#Frame: 50000, Loss: 0.000295
Last-10 average reward: -17.200000
#Frame: 60000, Loss: 0.000370
Last-10 average reward: -15.700000
#Frame: 70000, Loss: 0.000389
Last-10 average reward: -15.000000
#Frame: 80000, Loss: 0.000394
Last-10 average reward: -14.200000
#Frame: 90000, Loss: 0.000394
Last-10 average reward: -13.300000
#Frame: 100000, Loss: 0.000390
Last-10 average reward: -14.000000
#Frame: 110000, Loss: 0.000444
Last-10 average reward: -13.300000
#Frame: 120000, Loss: 0.000473
Last-10 average reward: -12.700000
#Frame: 130000, Loss: 0.000491
Last-10 average reward: -12.000000
#Frame: 140000, Loss: 0.000505
Last-10 average reward: -11.200000
#Frame: 150000, Loss: 0.000510
Last-10 average reward: -10.300000
#Frame: 160000, Loss: 0.000566
Last-10 average reward: -10.500000
#Frame: 170000, Loss: 0.000601
Last-10 average reward: -12.500000
#Frame: 180000, Loss: 0.000624
Last-10 average reward: -13.200000
#Frame: 190000, Loss: 0.000642
Last-10 average reward: -12.900000
#Frame: 200000, Loss: 0.000655
Last-10 average reward: -10.800000
#Frame: 210000, Loss: 0.000706
Last-10 average reward: -8.400000
#Frame: 220000, Loss: 0.000738
Last-10 average reward: -8.400000
#Frame: 230000, Loss: 0.000763
Last-10 average reward: -9.600000
#Frame: 240000, Loss: 0.000784
Last-10 average reward: -10.900000
#Frame: 250000, Loss: 0.000801
Last-10 average reward: -9.700000
#Frame: 260000, Loss: 0.000849
Last-10 average reward: -7.800000
#Frame: 270000, Loss: 0.000881
Last-10 average reward: -6.800000
#Frame: 280000, Loss: 0.000906
Last-10 average reward: -6.500000
#Frame: 290000, Loss: 0.000925
Last-10 average reward: -7.400000
#Frame: 300000, Loss: 0.000939
Last-10 average reward: -6.700000
#Frame: 310000, Loss: 0.000985
Last-10 average reward: -7.500000
#Frame: 320000, Loss: 0.001015
Last-10 average reward: -5.600000
#Frame: 330000, Loss: 0.001035
Last-10 average reward: -6.100000
#Frame: 340000, Loss: 0.001052
Last-10 average reward: -5.200000
#Frame: 350000, Loss: 0.001066
Last-10 average reward: -7.800000
#Frame: 360000, Loss: 0.001107
Last-10 average reward: -6.200000
#Frame: 370000, Loss: 0.001135
Last-10 average reward: -6.800000
#Frame: 380000, Loss: 0.001153
Last-10 average reward: -7.200000
#Frame: 390000, Loss: 0.001170
Last-10 average reward: -8.300000
#Frame: 400000, Loss: 0.001183
Last-10 average reward: -8.100000
#Frame: 410000, Loss: 0.001222
Last-10 average reward: -7.200000
#Frame: 420000, Loss: 0.001246
Last-10 average reward: -6.200000
#Frame: 430000, Loss: 0.001263
Last-10 average reward: -6.200000
#Frame: 440000, Loss: 0.001277
Last-10 average reward: -6.300000
#Frame: 450000, Loss: 0.001291
Last-10 average reward: -6.000000
#Frame: 460000, Loss: 0.001330
Last-10 average reward: -4.700000
#Frame: 470000, Loss: 0.001353
Last-10 average reward: -5.300000
#Frame: 480000, Loss: 0.001369
Last-10 average reward: -4.500000
#Frame: 490000, Loss: 0.001382
Last-10 average reward: -3.700000
#Frame: 500000, Loss: 0.001394
Last-10 average reward: -1.900000
Exception ignored in: <function WeakValueDictionary.__init__.<locals>.remove at 0x7f987e063268>
Traceback (most recent call last):
  File "/usr/lib/python3.5/weakref.py", line 117, in remove
TypeError: 'NoneType' object is not callable
Exception ignored in: <bound method ALEInterface.__del__ of <atari_py.ale_python_interface.ALEInterface object at 0x7f98de127f28>>
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/atari_py/ale_python_interface.py", line 354, in __del__
AttributeError: 'NoneType' object has no attribute 'ALE_del'
